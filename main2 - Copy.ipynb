{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7592210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazih\\AppData\\Local\\Temp\\ipykernel_15620\\1938280762.py:18: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  'dns': pd.read_csv('labeled_dataset_DNS_Spoofing.csv'),\n",
      "C:\\Users\\nazih\\AppData\\Local\\Temp\\ipykernel_15620\\1938280762.py:19: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  'mitm': pd.read_csv('labeled_dataset_MITM_ArpSpoofing.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(883525, 135)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"2\"\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load and combine datasets (as before)\n",
    "datasets = {\n",
    "    'benign': pd.read_csv('labeled_dataset_benign.csv'),\n",
    "    'dns': pd.read_csv('labeled_dataset_DNS_Spoofing.csv'),\n",
    "    'mitm': pd.read_csv('labeled_dataset_MITM_ArpSpoofing.csv')\n",
    "}\n",
    "combined_df = pd.concat([datasets['benign'], datasets['dns'], datasets['mitm']], ignore_index=True)\n",
    "combined_df = combined_df.drop('dst_mac', axis=1)\n",
    "\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a89a1a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "New shape after removing duplicates: (432555, 135)\n",
      "Categorical features: ['src_mac', 'src_ip', 'dst_ip', 'port_class_dst', 'l4_tcp', 'l4_udp', 'ttl', 'handshake_version', 'handshake_ciphersuites', 'tls_server', 'http_request_method', 'http_host', 'http_response_code', 'user_agent', 'dns_server', 'dns_query_type', 'dns_len_ans', 'device_mac', 'eth_src_oui', 'eth_dst_oui', 'highest_layer', 'http_uri', 'http_content_len', 'http_content_type', 'icmp_type', 'icmp_checksum_status', 'icmp_data_size', 'Label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazih\\AppData\\Local\\Temp\\ipykernel_15620\\1164603285.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['All_Labels'] = combined_df.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432555, 107)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def is_hex_mac(mac):\n",
    "    if pd.isna(mac) or mac == 'unknown':\n",
    "        return False\n",
    "    pattern = r'^([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})$'\n",
    "    return bool(re.match(pattern, str(mac)))\n",
    "\n",
    "\n",
    "combined_df = combined_df[~combined_df['src_mac'].apply(is_hex_mac)]\n",
    "\n",
    "# Drop duplicates\n",
    "print(f\"Number of duplicate rows: {combined_df.duplicated().sum()}\")\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "print(f\"New shape after removing duplicates: {combined_df.shape}\")\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = [col for col in combined_df.columns if combined_df[col].nunique() < 10 or combined_df[col].dtype == 'object']\n",
    "print(f\"Categorical features: {categorical_cols}\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    combined_df[col] = combined_df[col].astype(str).fillna('unknown')\n",
    "\n",
    "numerical_cols = combined_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "for col in numerical_cols:\n",
    "    combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n",
    "\n",
    "X = combined_df.drop(['Label', 'src_mac'], axis=1, errors='ignore')\n",
    "y_attack = combined_df['Label']\n",
    "y_device = combined_df['src_mac']\n",
    "\n",
    "# Encode device labels\n",
    "le_device = LabelEncoder()\n",
    "y_device_encoded = le_device.fit_transform(y_device)\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "combined_df['All_Labels'] = combined_df.apply(\n",
    "    lambda row: [row['Label'], row['src_mac']], axis=1\n",
    ")\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_multilabel = mlb.fit_transform(combined_df['All_Labels'])\n",
    "\n",
    "multilabel_class_names = mlb.classes_\n",
    "\n",
    "\n",
    "X_numeric = X.select_dtypes(include=['number'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_numeric)\n",
    "print(X_scaled.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a0d2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.multioutput import MultiOutputClassifier \n",
    "\n",
    "\n",
    "\n",
    "rf_estimator = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "target_features_to_keep = X_scaled.shape[1] // 3 \n",
    "\n",
    "\n",
    "\n",
    "rfe_selector = RFE(\n",
    "    estimator=rf_estimator, \n",
    "    n_features_to_select=target_features_to_keep, \n",
    "    step=5,\n",
    "    verbose=1 \n",
    ")\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled,       \n",
    "    Y_multilabel,       \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "251aee46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RFE to select 35 features based on the first label...\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 37 features.\n",
      "\n",
      "--- RFE Results ---\n",
      "Original Feature Count: 107\n",
      "Selected Feature Count: 35\n",
      "Selected Features: [0, 2, 5, 6, 7, 13, 16, 31, 40, 46, 55, 65, 68, 70, 71, 73, 75, 76, 80, 81, 83, 85, 86, 91, 93, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_single_label = Y_train[:, 0] \n",
    "\n",
    "print(f\"Starting RFE to select {target_features_to_keep} features based on the first label...\")\n",
    "\n",
    "\n",
    "rfe_selector.fit(X_train, Y_single_label)\n",
    "\n",
    "\n",
    "selected_mask = rfe_selector.support_\n",
    "\n",
    "selected_feature_names = X_train.columns[selected_mask]\n",
    "\n",
    "X_RFE_train = X_train[selected_feature_names]\n",
    "X_RFE_test = X_test[selected_feature_names] \n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- RFE Results ---\")\n",
    "print(f\"Original Feature Count: {X_train.shape[1]}\")\n",
    "print(f\"Selected Feature Count: {X_RFE_train.shape[1]}\")\n",
    "print(f\"Selected Features: {selected_feature_names.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb6e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting final Multi-Output Classifier using RFE-selected features...\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Train Final Multi-Label Model (Example: Simple RF) ---\n",
    "from sklearn.metrics import accuracy_score, jaccard_score, classification_report\n",
    "\n",
    "# Define a robust model to use the RFE features\n",
    "rf_base = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
    "final_model = MultiOutputClassifier(rf_base, n_jobs=-1)\n",
    "\n",
    "# Fit the final model using the RFE-selected features\n",
    "print(\"\\nFitting final Multi-Output Classifier using RFE-selected features...\")\n",
    "final_model.fit(X_RFE_train, Y_train)\n",
    "\n",
    "# --- 7. Evaluation ---\n",
    "Y_pred_rfe = final_model.predict(X_RFE_test)\n",
    "final_accuracy = accuracy_score(Y_test, Y_pred_rfe)\n",
    "final_jaccard = jaccard_score(Y_test, Y_pred_rfe, average='samples', zero_division=0)\n",
    "\n",
    "print(\"\\n--- Final Model Performance on RFE Features ---\")\n",
    "print(f\"Subset Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Jaccard Score: {final_jaccard:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
