{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7592210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazih\\AppData\\Local\\Temp\\ipykernel_19176\\1938280762.py:18: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  'dns': pd.read_csv('labeled_dataset_DNS_Spoofing.csv'),\n",
      "C:\\Users\\nazih\\AppData\\Local\\Temp\\ipykernel_19176\\1938280762.py:19: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  'mitm': pd.read_csv('labeled_dataset_MITM_ArpSpoofing.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(883525, 135)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"2\"\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load and combine datasets (as before)\n",
    "datasets = {\n",
    "    'benign': pd.read_csv('labeled_dataset_benign.csv'),\n",
    "    'dns': pd.read_csv('labeled_dataset_DNS_Spoofing.csv'),\n",
    "    'mitm': pd.read_csv('labeled_dataset_MITM_ArpSpoofing.csv')\n",
    "}\n",
    "combined_df = pd.concat([datasets['benign'], datasets['dns'], datasets['mitm']], ignore_index=True)\n",
    "combined_df = combined_df.drop('dst_mac', axis=1)\n",
    "\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89a1a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "New shape after removing duplicates: (432555, 135)\n",
      "Categorical features: ['src_mac', 'src_ip', 'dst_ip', 'port_class_dst', 'l4_tcp', 'l4_udp', 'ttl', 'handshake_version', 'handshake_ciphersuites', 'tls_server', 'http_request_method', 'http_host', 'http_response_code', 'user_agent', 'dns_server', 'dns_query_type', 'dns_len_ans', 'device_mac', 'eth_src_oui', 'eth_dst_oui', 'highest_layer', 'http_uri', 'http_content_len', 'http_content_type', 'icmp_type', 'icmp_checksum_status', 'icmp_data_size', 'Label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazih\\AppData\\Local\\Temp\\ipykernel_19176\\2122749699.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['All_Labels'] = combined_df.apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def is_hex_mac(mac):\n",
    "    if pd.isna(mac) or mac == 'unknown':\n",
    "        return False\n",
    "    pattern = r'^([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})$'\n",
    "    return bool(re.match(pattern, str(mac)))\n",
    "\n",
    "\n",
    "# Remove rows where src_mac is a real MAC address\n",
    "combined_df = combined_df[~combined_df['src_mac'].apply(is_hex_mac)]\n",
    "\n",
    "# Drop duplicates\n",
    "print(f\"Number of duplicate rows: {combined_df.duplicated().sum()}\")\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "print(f\"New shape after removing duplicates: {combined_df.shape}\")\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = [col for col in combined_df.columns if combined_df[col].nunique() < 10 or combined_df[col].dtype == 'object']\n",
    "print(f\"Categorical features: {categorical_cols}\")\n",
    "\n",
    "# Convert all categorical columns to string and fill missing with 'unknown'\n",
    "for col in categorical_cols:\n",
    "    combined_df[col] = combined_df[col].astype(str).fillna('unknown')\n",
    "\n",
    "# Fill missing numerical values with median\n",
    "numerical_cols = combined_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "for col in numerical_cols:\n",
    "    combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n",
    "\n",
    "# --- Step 2: Split target labels and features ---\n",
    "X = combined_df.drop(['Label', 'src_mac'], axis=1, errors='ignore')\n",
    "y_attack = combined_df['Label']\n",
    "y_device = combined_df['src_mac']\n",
    "\n",
    "# Encode device labels\n",
    "le_device = LabelEncoder()\n",
    "y_device_encoded = le_device.fit_transform(y_device)\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# 1. Create a column that holds both relevant labels as a list for each row\n",
    "# This creates a list ['Attack_Name', 'Device_MAC'] for every packet\n",
    "combined_df['All_Labels'] = combined_df.apply(\n",
    "    lambda row: [row['Label'], row['src_mac']], axis=1\n",
    ")\n",
    "\n",
    "# 2. Initialize and fit the binarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_multilabel = mlb.fit_transform(combined_df['All_Labels'])\n",
    "\n",
    "# 3. Store the column names (needed for evaluation later)\n",
    "multilabel_class_names = mlb.classes_\n",
    "\n",
    "\n",
    "# Keep only numeric columns\n",
    "X_numeric = X.select_dtypes(include=['number'])\n",
    "\n",
    "# Normalize features using StandardScaler (zero mean, unit variance)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "# Apply PCA to retain 95% variance\n",
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X_scaled)\n",
    "\n",
    "pca_feature_names = [f'PC{i+1}' for i in range(X_reduced.shape[1])]\n",
    "\n",
    "# Convert to DataFrame for ease of use\n",
    "X_reduced_df = pd.DataFrame(X_reduced, columns=pca_feature_names, index=X.index)\n",
    "\n",
    "# Replace the single-label splits with the multi-label split:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_reduced_df,       # Your PCA features\n",
    "    Y_multilabel,       # Your multi-label target matrix\n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa2ba546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Multi-Label LightGBM ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, jaccard_score, hamming_loss, classification_report\n",
    "\n",
    "# --- 1. Define the Base Estimator (LightGBM) ---\n",
    "print(\"--- Training Multi-Label LightGBM ---\")\n",
    "# Apply regularization and weighted loss to the base model\n",
    "lgb_base = lgb.LGBMClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    n_jobs=2,\n",
    "    max_depth=8,              # Regularization: Limit tree depth\n",
    "    reg_alpha=0.2,            # Regularization: L1\n",
    "    # Weighted Loss: Applies balancing to each of the output's binary problems\n",
    "    class_weight='balanced'   \n",
    ")\n",
    "\n",
    "# --- 2. Wrap it with MultiOutputClassifier ---\n",
    "# This trains M LightGBM models (where M is the number of total unique labels)\n",
    "lgb_multioutput = MultiOutputClassifier(lgb_base, n_jobs=-1)\n",
    "\n",
    "# --- 3. Fit the Model ---\n",
    "# This will take longer than a single multi-class model\n",
    "lgb_multioutput.fit(X_train, Y_train)\n",
    "\n",
    "# --- 4. Prediction ---\n",
    "Y_pred_lgbm = lgb_multioutput.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee46c5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Evaluation: LightGBM Multi-Output ========\n",
      "Subset Accuracy (Exact Match): 0.6805\n",
      "Jaccard Score (Label Similarity): 0.8285\n",
      "Hamming Loss (Error Rate): 0.0157\n",
      "\n",
      "--- Micro-Averaged Metrics (Focus on Total Correctness) ---\n",
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "                       AMCREST WiFi Camera       0.30      0.97      0.46       473\n",
      "                     AeoTec Smart Home Hub       0.33      0.97      0.49      1014\n",
      "                         Amazon Echo Dot 1       0.25      0.96      0.40      1503\n",
      "                         Amazon Echo Dot 2       0.79      0.99      0.88      5075\n",
      "                          Amazon Echo Show       0.73      0.97      0.83      5430\n",
      "                          Amazon Echo Spot       0.55      0.97      0.70      3409\n",
      "                        Amazon Echo Studio       0.99      0.98      0.99     32421\n",
      "                               Amazon Plug       0.46      0.91      0.61       109\n",
      "                         Arlo Base Station       0.55      0.97      0.70      1812\n",
      "                      Arlo Q Indoor Camera       0.72      0.98      0.83      2125\n",
      "                        Atomi Coffee Maker       0.24      0.96      0.38       454\n",
      "                             BenignTraffic       0.92      0.99      0.96     26077\n",
      "                   Borun/Sichuan-AI Camera       0.52      0.97      0.68       738\n",
      "                     Cocoon Smart HVAC Fan       0.47      0.96      0.63       422\n",
      "            DCS8000LHA1 D-Link Mini Camera       0.97      0.97      0.97       193\n",
      "                              DNS_Spoofing       0.95      0.97      0.96     28732\n",
      "                           Eufy HomeBase 2       0.35      0.97      0.51       690\n",
      "                     Globe Lamp ESP_B1680C       0.12      0.94      0.21       294\n",
      "                               GoSund Bulb       0.26      0.96      0.41       379\n",
      "                    GoSund Power strip (2)       0.13      0.97      0.23       647\n",
      "                 GoSund Smart Plug WP2 (2)       0.15      0.97      0.26       647\n",
      "                 GoSund Smart Plug WP3 (1)       0.14      0.95      0.25       646\n",
      "                 GoSund Smart plug WP2 (1)       0.17      0.97      0.29       670\n",
      "                 GoSund Smart plug WP2 (3)       0.15      0.97      0.25       618\n",
      "                  Google Nest Mini Speaker       0.65      0.98      0.78      2703\n",
      "                    Gosund Power strip (1)       0.15      0.97      0.26       671\n",
      "                 Gosund Smart Plug WP3 (2)       0.17      0.97      0.29       627\n",
      "                     Govee Smart Humidifer       0.50      0.85      0.63        67\n",
      "              HeimVision Smart WiFi Camera       0.93      0.99      0.96       919\n",
      "           HeimVision SmartLife Radio/Lamp       0.36      0.97      0.52       522\n",
      "                           Home Eye Camera       0.62      0.98      0.76      1429\n",
      "                            LIFX Lightbulb       0.63      0.95      0.75       172\n",
      "                                LampUX RGB       0.14      0.98      0.24       619\n",
      "                       Levoit Air Purifier       0.59      0.95      0.73       345\n",
      "                              Lumiman bulb       0.89      0.98      0.93       446\n",
      "                             Luohe Cam Dog       0.50      0.75      0.60         8\n",
      "                          MITM-ArpSpoofing       0.99      0.99      0.99     31702\n",
      "                        Nest Indoor Camera       0.97      0.99      0.98      3123\n",
      "                            Netatmo Camera       0.45      0.97      0.62      1297\n",
      "                   Netatmo Weather Station       0.88      0.98      0.93       473\n",
      "                        Philips Hue Bridge       0.71      0.98      0.82      1402\n",
      "                       Raspberry Pi 4-2 GB       0.16      0.50      0.25        16\n",
      "                             Rbcior Camera       0.29      0.97      0.44       844\n",
      "                      SIMCAM 1S (AMPAKTec)       0.71      0.89      0.79        28\n",
      "                               Smart Board       0.17      0.93      0.28       162\n",
      "                           SmartThings Hub       0.57      0.99      0.72      1913\n",
      "                         Sonos One Speaker       0.21      0.92      0.35       376\n",
      "                       TP-Link Tapo Camera       0.27      0.92      0.41       331\n",
      "                        Teckin Light Strip       0.45      0.97      0.61       462\n",
      "                             Teckin Plug 1       0.23      0.93      0.37       411\n",
      "                             Teckin Plug 2       0.32      0.95      0.48       429\n",
      "Wemo smart plug 1 (Wemo id: Wemo.Mini.AD3)       0.17      0.65      0.27        31\n",
      "Wemo smart plug 2 (Wemo id: Wemo.Mini.4A3)       0.25      0.89      0.39       108\n",
      "                               Wyze Camera       0.42      0.98      0.59      2170\n",
      "                        Yi Indoor 2 Camera       0.86      0.98      0.91      1735\n",
      "                          Yi Indoor Camera       0.35      0.91      0.50       312\n",
      "                         Yi Outdoor Camera       0.34      0.92      0.50       287\n",
      "                             Yutron Plug 1       0.23      0.93      0.36       405\n",
      "                             Yutron Plug 2       0.25      0.95      0.39       415\n",
      "          harman kardon (Ampak Technology)       0.38      0.97      0.55      1328\n",
      "                             iRobot Roomba       0.81      0.93      0.87       156\n",
      "\n",
      "                                 micro avg       0.68      0.98      0.80    173022\n",
      "                                 macro avg       0.47      0.94      0.59    173022\n",
      "                              weighted avg       0.84      0.98      0.88    173022\n",
      "                               samples avg       0.83      0.98      0.87    173022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_multilabel_model(Y_test, Y_pred, class_names):\n",
    "    \"\"\"Calculates and prints key multi-label metrics.\"\"\"\n",
    "    print(\"\\n======== Evaluation: LightGBM Multi-Output ========\")\n",
    "    \n",
    "    # 1. Subset Accuracy (STRICTEST: Requires *ALL* labels to match exactly)\n",
    "    subset_acc = accuracy_score(Y_test, Y_pred)\n",
    "    print(f\"Subset Accuracy (Exact Match): {subset_acc:.4f}\")\n",
    "\n",
    "    # 2. Jaccard Score (Average of Intersection over Union)\n",
    "    # This is often the most informative metric for multi-label\n",
    "    jaccard = jaccard_score(Y_test, Y_pred, average='samples')\n",
    "    print(f\"Jaccard Score (Label Similarity): {jaccard:.4f}\")\n",
    "\n",
    "    # 3. Hamming Loss (Fraction of incorrect labels)\n",
    "    # Lower is better; a perfect score is 0.0\n",
    "    hamming = hamming_loss(Y_test, Y_pred)\n",
    "    print(f\"Hamming Loss (Error Rate): {hamming:.4f}\")\n",
    "    \n",
    "    # 4. Detailed Per-Label Metrics (Micro/Macro averages)\n",
    "    print(\"\\n--- Micro-Averaged Metrics (Focus on Total Correctness) ---\")\n",
    "    # Note: Target names should come from the mlb.classes_ variable\n",
    "    print(classification_report(Y_test, Y_pred, \n",
    "                                target_names=class_names, \n",
    "                                zero_division=0, \n",
    "                                output_dict=False))\n",
    "\n",
    "# Run the evaluation\n",
    "evaluate_multilabel_model(Y_test, Y_pred_lgbm, multilabel_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d117605e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
